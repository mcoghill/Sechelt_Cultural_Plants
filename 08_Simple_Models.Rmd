---
title: "08_Simple_Models"
author: "Matthew Coghill"
date: "12/18/2020"
output: html_document
self_contained: no
---

Following the meeting on Wednesday, December 16, we felt that some simplified base models should be created using the original groupings of variables, rather than testing multiple different groups. This makes really good sense and perhaps should have been done before...oops!

This will use the same scripting setup as the other modelling scripts, just more directed. First, we want to just see terrain variables on salmonberry and see what kind of output that produces. Just focus on the 2020 data for now as well.

```{r Load Packages}

invisible(suppressPackageStartupMessages(
  lapply(c("tidyverse", "terra", "sf", "mlr3verse", "corrplot", "ranger"), 
         library, character.only = TRUE)))

# Load custom scripts
source("./_functions/model_gen_mlr3_binary_simple.R")

```

Next, define the locations and options for where files are located and how to continue processing.

```{r Define directories}

AOI <- "Sechelt"
AOI_dir <- file.path(".", paste0(AOI, "_AOI"))
map_res <- 4
res_dir <- ifelse(is.numeric(map_res), paste0(map_res, "m"), map_res)

input_dir <- file.path(
  "./Sechelt_AOI/1_map_inputs/field_data/processed_2020", res_dir)
covariate_dir <- file.path(AOI_dir, "1_map_inputs", "covariates", res_dir)
shapes_dir <- file.path(AOI_dir, "0_raw_inputs", "base_layers", res_dir)
dsmart_site_ser_dir <- file.path(AOI_dir, "1_map_inputs", "dsmart_2020", 
                                 res_dir, "site_ser")
dsmart_struct_stg_dir <- file.path(AOI_dir, "1_map_inputs", "dsmart_2020", 
                                   res_dir, "struct_stg")
output_dir <- file.path(AOI_dir, "8_map_predictions_simple", res_dir)
tile_dir <- file.path(output_dir, "tiles")

dir.create(tile_dir, showWarnings = FALSE, recursive = TRUE)
dir.create(file.path(output_dir, "pres_abs_predictions"), showWarnings = FALSE)
dir.create(file.path(output_dir, "cover_predictions"), showWarnings = FALSE)

```

Next, load the data and define processing options. This is modified from the 04c script.

```{r Load data}

s_pattern <- "sentinel2.*.2019.tif$"
# c_pattern <- "normal(?!.*(_at.tif|_sm.tif|_sp.tif|_wt.tif))"
c_pattern <- "normal_1981_2010y.*..tif"

cov_fun <- function() { 
  
  # DSMART layers
  site_ser_dsmart_probs <- rast(list.files(
    file.path(dsmart_site_ser_dir, "output", "probabilities"), full.names = TRUE)) %>% 
    setNames(paste0("dsmart_site_ser_probability_", names(.)))
  
  site_ser_dsmart_class <- rast(file.path(dsmart_site_ser_dir, "site_ser_dsmart.tif")) %>% 
    setNames("dsmart_site_ser_class") %>% 
    as.factor()
  
  dsmart_class_labels <- data.frame(levels = levels(site_ser_dsmart_class)[[1]]$levels,
                                    code = levels(site_ser_dsmart_class)[[1]]$labels)
  
  dsmart_class_lut <- read.table(file.path(dsmart_site_ser_dir, "output", "lookup.txt"), 
                                 sep = ",", header = TRUE) %>% 
    merge(dsmart_class_labels) %>% 
    dplyr::select(levels, name)
  
  levels(site_ser_dsmart_class) <- dsmart_class_lut
  
  # Simple site series layers
  site_ser_simple_probs <- rast(grep(
    "site_series_simple.tif", 
    list.files(file.path(dsmart_site_ser_dir, "simple"), full.names = TRUE, pattern = ".tif$"),
    invert = TRUE, value = TRUE)) %>% 
    setNames(paste0("simple_site_ser_", names(.)))
  
  site_ser_simple_class <- rast(file.path(dsmart_site_ser_dir, "simple", "site_series_simple.tif")) %>% 
    setNames("simple_site_ser_class") %>% 
    as.factor()
  
  simple_class_labels <- data.frame(levels = levels(site_ser_simple_class)[[1]]$levels,
                                    code = levels(site_ser_simple_class)[[1]]$labels)
  
  simple_class_lut <- read.table(file.path(dsmart_site_ser_dir, "simple", 
                                           "site_ser_simple_lookup.txt"), 
                                 sep = ",", header = TRUE) %>% 
    merge(simple_class_labels) %>% 
    dplyr::select(levels, name)
  
  levels(site_ser_simple_class) <- simple_class_lut
  
  # Terrain Raster covariates only
  terrain_covariates <- rast(grep(pattern = "normal|sentinel2|chm", list.files(
    covariate_dir, full.names = TRUE, pattern = ".tif$"), 
    invert = TRUE, value = TRUE))
  
  # Climate Raster covariates only
  climate_covariates <- rast(list.files(covariate_dir, pattern = c_pattern, 
                                       full.names = TRUE))
  
  # Satellite indices
  satellite_covariates <- rast(grep(file.path(covariate_dir, s_pattern), 
                                   list.files(covariate_dir, full.names = TRUE), 
                                   value = TRUE, perl = TRUE))
  
  return(list(terrain_covariates = terrain_covariates, 
              climate_covariates = climate_covariates,
              satellite_covariates = satellite_covariates, 
              site_ser_dsmart_probs = site_ser_dsmart_probs,
              site_ser_dsmart_class = site_ser_dsmart_class,
              site_ser_simple_probs = site_ser_simple_probs,
              site_ser_simple_class = site_ser_simple_class))
  
}
covariates <- cov_fun()

cov_atts <- unlist(sapply(covariates, names), use.names = FALSE)

# Read in attributed point data
pres_abs <- sapply(c("Corn can", "Rubu spe"), function(x) {
  st_read(file.path(input_dir, "pres_abs.gpkg"), layer = x, quiet = TRUE) %>% 
    mutate(across("Pres", as.factor)) %>%
    dplyr::select(Pres, cov_atts[cov_atts %in% names(.)])
  }, simplify = FALSE, USE.NAMES = TRUE)

# Determine missing covariates and create a SpatRaster of those
missing_covs <- cov_atts[!cov_atts %in% names(pres_abs[[1]])] %>% 
  lapply(X = covariates, FUN = function(x, y = .) 
    subset(x, y[y %in% names(x)])) %>% compact() %>% 
  Reduce(c, .)

# Extract missing data to pres_abs
pres_abs <- lapply(pres_abs, function(x) {
  x %>% cbind(terra::extract(missing_covs, st_coordinates(.)))})

# Write input data
dir_out <- file.path(output_dir, "pres_abs_predictions")
dir.create(dir_out, showWarnings = FALSE, recursive = TRUE)
invisible(lapply(names(pres_abs), function(x) {
  st_write(pres_abs[[x]], file.path(dir_out, paste0("pres_abs_input_data.gpkg")), 
           layer = x, delete_layer = TRUE, quiet = TRUE)
}))

```

Perform modelling for each covariate group. Within each group, there are 2 different types of models run: A normal cross validated model and a spatially cross validated model. Results are compared at the end for the decision of the best model to use in map prediction.

```{r mlr3 Presence probability modelling}

models <- sapply(names(covariates), function(j) {
  
  # Select the covariate group to use
  covariates_flt <- covariates[[j]]
  
  # Only select the point columns containing the covariate names, and omit rows
  # containing NA values
  pres_abs_flt <- lapply(pres_abs, function(x) 
    dplyr::select(x, any_of(c("Pres", names(covariates_flt)))) %>% 
      drop_na())
  
  # Filter down the covariates to only include the ones that weren't filtered 
  # out based on the mask_layer variable
  covariates_flt <- subset(
    covariates_flt, names(pres_abs_flt[[1]])[
      !names(pres_abs_flt[[1]]) %in% c("Pres", attr(pres_abs_flt[[1]], "sf_column"))])
  
  sp_models <- lapply(1:length(pres_abs_flt), function(i) {
    
    dir_out <- file.path(output_dir, "pres_abs_predictions", names(pres_abs_flt[i]), j)
    dir.create(dir_out, showWarnings = FALSE, recursive = TRUE)
    
    # Create models for each dataset. Each model is a 10-fold spatial cross validation
    # repeated 5 times.
    # traindat = pres_abs_flt[[i]]
    # target = "Pres"
    # filter_correlation = TRUE
    # corr_cutoff = 0.95
    # positive = "TRUE"
    # id = names(pres_abs_flt)[i]
    # covariates = covariates_flt
    # outDir = dir_out
    # folds = 10
    # repeats = 5
    # rfe = FALSE
    
    pres_model <- model_gen_mlr3_binary_simple(traindat = pres_abs_flt[[i]], target = "Pres",
                                  filter_correlation = TRUE, corr_cutoff = 0.95,
                                  positive = "TRUE", rfe = FALSE,
                                  id = names(pres_abs_flt)[i], covariates = covariates_flt,
                                  outDir = dir_out)
    
  }) %>% setNames(names(pres_abs_flt))
}, simplify = FALSE, USE.NAMES = TRUE)

```

Using the files created with the model metrics, evaluate which model is best from the mean scores and then run map predictions for each covariate group. I make use of the `terra` package here to do predictions, since it keeps things consistent; however, I notice that with high resolution data, making predictions on a single layer is very taxing on a computer and sometimes causes R to crash. Fret not - if that is the case, you don't need to perform the modelling step again. Just run the sections above the modelling chunk and come back here and filter the results to only the rows that require further prediction. It seems that often times, just having a fresh session works to solve that issue. A possible fix is to perform the predictions in `raster`, but there are extra steps involved with that which make the process less intuitive (i.e.: setting covariate names and setting CRS info after prediction, then converting back to a `SpatRaster` object.)

```{r Results and map prediction}

sp <- names(pres_abs)
cov_grps <- names(covariates)
results <- bind_rows(lapply(sp, function(x) {
  bind_rows(lapply(cov_grps, function(y) {
    read.csv(file.path(output_dir, "pres_abs_predictions", x, y, "run_compare.csv")) %>% 
      dplyr::slice_max(mean_fbeta, n = max(2, nrow(.) * (1/3))) %>% 
      dplyr::slice_min(mean_bbrier, with_ties = FALSE) %>% 
      dplyr::mutate(species = x, cov_group = y, .before = 1)
  }))
}))

# Write results
for(i in sp) {
  invisible(dplyr::filter(results, species == i) %>%
    write.csv(file.path(output_dir, "pres_abs_predictions", i,
                         paste0(i, "_results.csv")), row.names = FALSE))
}

# This can help filter the results if your R session crashed
# results <- results[c(7:nrow(results)), ]

# Run map predictions for best results
terraOptions(memfrac = 0.1)
best_preds <- rast(lapply(1:nrow(results), function(x) {
  sp <- results[x, ]$species
  cov_grp <- results[x, ]$cov_group
  run <- results[x, ]$task_id
  out <- file.path(output_dir, "pres_abs_predictions", sp, cov_grp)
  model <- readRDS(file.path(out, run, "best_model.rds"))
  covs <- subset(covariates[[cov_grp]], names(model$variable.importance))
  wopt <- list(names = "TRUE")
  pred <- terra::predict(
    covs, model, na.rm = TRUE,
    fun = function(model, ...) predict(model, verbose = FALSE, ...)$predictions,
    index = 1L,
    filename = file.path(out, paste0(wopt$names, ".tif")), overwrite = TRUE,
    wopt = wopt)
  # covs <- stack(subset(covariates[[cov_grp]], names(model$variable.importance)))
  # crs(covs) <- crs(covariates[[cov_grp]])
  # names(covs) <- names(subset(covariates[[cov_grp]], names(model$variable.importance)))
  # pred <- rast(raster::predict(
  #   covs, model, na.rm = TRUE,
  #   fun = function(model, ...) predict(model, verbose = FALSE, ...)$predictions,
  #   index = 1L), crs = crs(covariates[[cov_grp]])) %>%
  #   writeRaster(file.path(out, "TRUE.tif"), overwrite = TRUE, wopt = list(names = "TRUE"))
}))

```

