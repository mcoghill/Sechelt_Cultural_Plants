---
title: "08_Simple_Models"
author: "Matthew Coghill"
date: "12/18/2020"
output: html_document
self_contained: no
---

Following the meeting on Wednesday, December 16, we felt that some simplified base models should be created using the original groupings of variables, rather than testing multiple different groups. This makes really good sense and perhaps should have been done before...oops!

This will use the same scripting setup as the other modelling scripts, just more directed. First, we want to just see terrain variables on salmonberry and see what kind of output that produces. Just focus on the 2020 data for now as well.

```{r Load Packages}

invisible(suppressPackageStartupMessages(
  lapply(c("tidyverse", "tools", "terra", "sf", "mlr3verse", "corrplot"), 
         library, character.only = TRUE)))

# Load custom scripts
source("./_functions/model_gen_mlr3.R")
source("./_functions/predict_landscape_mlr3.R")

```

Next, define the locations and options for where files are located and how to continue processing.

```{r Define directories}

AOI <- "Sechelt"
AOI_dir <- file.path(".", paste0(AOI, "_AOI"))
map_res <- 10
res_dir <- ifelse(is.numeric(map_res), paste0(map_res, "m"), map_res)

input_dir <- file.path(
  "./Sechelt_AOI/1_map_inputs/field_data/processed_2020", res_dir)
covariate_dir <- file.path(AOI_dir, "1_map_inputs", "covariates", res_dir)
shapes_dir <- file.path(AOI_dir, "0_raw_inputs", "base_layers", res_dir)
dsmart_site_ser_dir <- file.path(AOI_dir, "1_map_inputs", "dsmart_2020", 
                                 res_dir, "site_ser")
dsmart_struct_stg_dir <- file.path(AOI_dir, "1_map_inputs", "dsmart_2020", 
                                   res_dir, "struct_stg")
output_dir <- file.path(AOI_dir, "8_map_predictions_simple", res_dir)
tile_dir <- file.path(output_dir, "tiles")

dir.create(tile_dir, showWarnings = FALSE, recursive = TRUE)
dir.create(file.path(output_dir, "pres_abs_predictions"), showWarnings = FALSE)
dir.create(file.path(output_dir, "cover_predictions"), showWarnings = FALSE)

```

Next, load the data and define processing options. This is modified from the 04c script.

```{r Load data}

s_pattern <- "sentinel2.*.2019.tif$"
c_pattern <- "normal(?!.*(_at.tif|_sm.tif|_sp.tif|_wt.tif))"

covariates <- list(
  # Terrain Raster covariates only
  terrain_covariates = rast(grep(pattern = "normal|sentinel2|chm", list.files(
    covariate_dir, full.names = TRUE, pattern = ".tif$"), 
    invert = TRUE, value = TRUE)),
  
  # Climate Raster covariates only
  climate_covariates = rast(grep(file.path(covariate_dir, c_pattern),
                                 list.files(covariate_dir, full.names = TRUE), 
                                 value = TRUE, perl = TRUE)),
  
  # Satellite indices
  satellite_covariates = rast(grep(file.path(covariate_dir, s_pattern), 
                                   list.files(covariate_dir, full.names = TRUE), 
                                   value = TRUE, perl = TRUE)),
  
  # DSMART layers
  site_ser_dsmart_probs = rast(list.files(
    file.path(dsmart_site_ser_dir, "output", "probabilities"), full.names = TRUE)) %>% 
    setNames(paste0("dsmart_site_ser_probability_", names(.))),
  
  site_ser_dsmart_class = rast(file.path(dsmart_site_ser_dir, "site_ser_dsmart.tif")) %>% 
    setNames("dsmart_site_ser_class"),
  
  # Simple site series layers
  site_ser_simple_probs = rast(grep(
    "site_series_simple.tif", 
    list.files(file.path(dsmart_site_ser_dir, "simple"), full.names = TRUE, pattern = ".tif$"),
    invert = TRUE, value = TRUE)) %>% 
    setNames(paste0("simple_site_ser_", names(.))),
  
  site_ser_simple_class = rast(file.path(dsmart_site_ser_dir, "simple", "site_series_simple.tif")) %>% 
    setNames("simple_site_ser_class")
)

# Find the best masking layer to use in the predict_landscape algorithm
# Also filter out grossly incorrect rasters
mask_layers <- lapply(covariates, function(x) {
  sapply(names(x), function(y) {
    cat(paste0("\rCounting NA values in ", y, " [", which(names(x) == y), 
               " of ", nlyr(x), "]\n"))
    unname(freq(subset(x, y) * 0)[, "count"])}) %>% 
    data.frame(data_cells = .) %>% 
    rownames_to_column("layer")}) %>% 
  do.call(rbind, .) %>% 
  arrange(desc(data_cells)) %>% 
  remove_rownames()

cov_atts <- unlist(sapply(covariates, names), use.names = FALSE)

# Read in attributed point data
pres_abs <- sapply(c("Corn can", "Rubu spe"), function(x) {
  st_read(file.path(input_dir, "pres_abs.gpkg"), layer = x, quiet = TRUE) %>% 
    mutate(across("Pres", as.factor)) %>%
    dplyr::select(Pres, cov_atts[cov_atts %in% names(.)])
  }, simplify = FALSE, USE.NAMES = TRUE)

# Determine missing covariates and create a SpatRaster of those
missing_covs <- cov_atts[!cov_atts %in% names(pres_abs[[1]])] %>% 
  lapply(X = covariates, FUN = function(x, y = .) 
    subset(x, y[y %in% names(x)])) %>% compact() %>% 
  Reduce(c, .)

# Extract missing data to pres_abs
pres_abs <- lapply(pres_abs, function(x) {
  x %>% cbind(terra::extract(missing_covs, st_coordinates(.)))})

# Write input data
dir_out <- file.path(output_dir, "pres_abs_predictions")
dir.create(dir_out, showWarnings = FALSE, recursive = TRUE)
invisible(lapply(names(pres_abs), function(x) {
  st_write(pres_abs[[x]], file.path(dir_out, paste0("pres_abs_input_data.gpkg")), 
           layer = x, delete_layer = TRUE, quiet = TRUE)
}))

```



```{r mlr3 Presence probability modelling}

# To save a bit of memory and in order to see results as they are generated, 
# iterate through the list of input data to model and predict

for(j in names(covariates)) {
  
  # Select the covariate group to use
  covariates_flt <- covariates[[j]]
  
  # Only select the point columns containing the covariate names, and omit rows
  # containing NA values
  pres_abs_flt <- lapply(pres_abs, function(x) 
    dplyr::select(x, any_of(c("Pres", names(covariates_flt)))) %>% 
      drop_na())
  
  # Filter down the covariates to only include the ones that weren't filtered 
  # out based on the mask_layer variable
  covariates_flt <- subset(
    covariates_flt, names(pres_abs_flt[[1]])[
      !names(pres_abs_flt[[1]]) %in% c("Pres", attr(pres_abs_flt[[1]], "sf_column"))])
  
  for(i in 1:length(pres_abs_flt)) {
    
    dir_out <- file.path(output_dir, "pres_abs_predictions", names(pres_abs_flt[i]), j)
    dir.create(dir_out, showWarnings = FALSE, recursive = TRUE)
    
    # Create models for each dataset. Each model is a 10-fold spatial cross validation
    # repeated 5 times.
    pres_models <- model_gen_mlr3(traindat = pres_abs_flt[i], target = "Pres", 
                                  filter_correlation = TRUE, feature_selection = "rfe", 
                                  type = "prob")
    
    # Extract and write performance metrics
    pres_performance <- sapply(names(pres_models$learners), function(x) {
      
      folds <- pres_models$learners[[x]]$instance_args$resampling$param_set$values$folds
      reps <- pres_models$learners[[x]]$instance_args$resampling$param_set$values$repeats
      n_iters <- pres_models$learners[[x]]$archive$benchmark_result$n_resample_results
      
      cor_matrix <- pres_models$cor_matrix[[x]]
      
      tune_results <- pres_models$learners[[x]]$archive$data() %>% 
        dplyr::select(-c(uhash, x_domain, timestamp)) %>% 
        dplyr::arrange(classif.ce)
      
      confusion <- as.data.frame(
        pres_models$learners[[x]]$model$fselect_instance$archive$benchmark_result$
          resample_results$resample_result[[
            pres_models$learners[[x]]$model$fselect_instance$archive$best()$batch_nr]]$
          prediction()$confusion)
      
      metrics <- data.frame(
        metric = c("Accuracy", "Error", "Sensitivity", "Specificty"),
        result = c(
          (dplyr::filter(confusion, response == truth) %>% 
             dplyr::pull(Freq) %>% sum()) / 
            sum(confusion$Freq),
          (dplyr::filter(confusion, response != truth) %>% 
             dplyr::pull(Freq) %>% sum()) / 
            sum(confusion$Freq),
          (dplyr::filter(confusion, response == TRUE & truth == TRUE) %>% 
             dplyr::pull(Freq)) / 
            sum(
              (dplyr::filter(confusion, response == TRUE & truth == TRUE) %>% 
                 dplyr::pull(Freq)),
              (dplyr::filter(confusion, response == TRUE & truth == FALSE) %>% 
                 dplyr::pull(Freq))
            ),
          (dplyr::filter(confusion, response == FALSE & truth == FALSE) %>% 
             dplyr::pull(Freq)) / 
            sum(
              (dplyr::filter(confusion, response == FALSE & truth == TRUE) %>% 
                 dplyr::pull(Freq)),
              (dplyr::filter(confusion, response == FALSE & truth == FALSE) %>% 
                 dplyr::pull(Freq))
            )
        )
      )
      
      model_data <- lapply(1:n_iters, function(j) {
        test_data <- pres_models$learners[[x]]$archive$benchmark_result$resample_result(j)$
          resampling$instance %>% 
          cbind(batch_nr = j)
        train_data <- do.call(rbind, lapply(1:reps, function(k) {
          do.call(rbind, lapply(1:folds, function(l) {
            test_rows <- dplyr::filter(test_data, rep == k, fold == l)
            missing <- as.numeric(rownames(pres_abs_flt[[i]])[
              !as.numeric(rownames(pres_abs_flt[[i]])) %in% test_rows$row_id])
            data.frame(row_id = missing, rep = k, fold = l, batch_nr = j)
          }))
        }))
        return(list(test_data = test_data, train_data = train_data))
      }) %>% setNames(paste0(
        "batch_nr = ", 
        pres_models$learners[[x]]$model$fselect_instance$archive$data()$
          batch_nr))
      
      train_data <- do.call(rbind, lapply(model_data, "[[", "train_data")) %>% 
        magrittr::set_rownames(NULL)
      test_data <- do.call(rbind, lapply(model_data, "[[", "test_data")) %>% 
        magrittr::set_rownames(NULL)
      
      imp <- data.frame(importance = pres_models$learners[[x]]$learner$model$
                          variable.importance) %>% 
        rownames_to_column("layer") %>% 
        arrange(desc(importance))
      
      out <- utils::capture.output(pres_models$learners[[x]]$learner$model)
      best_model <- pres_models$learners[[x]]$learner$model
      
      write.csv(tune_results, file = file.path(dir_out, paste0(x, "_pres_abs_tune_results.csv")),
                row.names = FALSE)
      cat(out, file = file.path(dir_out, paste0(x, "_pres_abs_model.txt")), sep = "\n")
      save(best_model, file = file.path(dir_out, paste0(x, "_pres_abs_model.RData")))
      write.csv(test_data, file = file.path(
        dir_out, paste0(x, "_pres_abs_model_resampling_test_data.csv")), 
        row.names = FALSE)
      write.csv(train_data, file = file.path(
        dir_out, paste0(x, "_pres_abs_model_resampling_train_data.csv")), 
        row.names = FALSE)
      write.csv(confusion, file = file.path(dir_out, paste0(x, "_pres_abs_confusion.csv")), 
                row.names = FALSE)
      write.csv(imp, file.path(dir_out, paste0(x, "_pres_abs_var_importance.csv")), 
                row.names = FALSE)
      write.csv(pres_abs_flt[i][[x]], file.path(dir_out, paste0(x, "_pres_abs_input_data.csv")), 
                row.names = FALSE)
      write.csv(metrics, file.path(dir_out, paste0(x, "_pres_abs_model_metrics.csv")), 
                row.names = FALSE)
      write.csv(cor_matrix, file.path(dir_out, paste0(x, "_pres_abs_correlation_matrix.csv")), 
                row.names = TRUE)
      
      # Save correlation image
      cor_out <- function() {
        pal <- colorRampPalette(c("green", "white", "red")) (20)
        png(file.path(dir_out, paste0(x, "_pres_abs_pearson_correlation.jpg")),
            height = 960, width = 960)
        corrplot(cor_matrix)
        # heatmap(cor_matrix, col = pal, symm = TRUE)
        dev.off()
        return(invisible())
      }
      cor_out()
      
      return(list(
        tune_results = tune_results,
        metrics = metrics,
        best_model = best_model, 
        resampling = test_data,
        confusion = confusion,
        importance = imp, 
        cor_matrix = cor_matrix
      ))
      
    }, simplify = FALSE, USE.NAMES = TRUE)
    
    # Run the map predictions
    pres_abs_predictions <- sapply(names(pres_models$learners), function(x) {
      
      cov_sub <- subset(covariates_flt, pres_models$tasks[[x]]$col_roles$feature)
      
      # Find the best mask layer to use from the covariates left
      pred_mask <- mask_layers %>% 
        dplyr::filter(layer %in% names(cov_sub)) %>% 
        dplyr::arrange(layer) %>% 
        dplyr::slice_max(data_cells, n = 1, with_ties = FALSE) %>% 
        dplyr::pull(layer)
      
      out <- predict_landscape_mlr3(
        learner = pres_models$learners[[x]],
        task = pres_models$tasks[[x]], 
        type = "prob",
        covariates = cov_sub,
        tilesize = 500, 
        outDir = tile_dir, 
        mask_layer = pred_mask)
      
      # Write the raster mosaics
      out <- writeRaster(out, file.path(
        dir_out, paste0(x, "_", gsub("_.*", "", names(out)), ".tif")),
        overwrite = TRUE)
      
    }, simplify = FALSE, USE.NAMES = TRUE)
  }
}

# Using the available model results, find the best models for each species
best_model_sets <- lapply(c("Corn can", "Rubu spe"), function(x) {
  sp_dirs <- list.dirs(file.path(output_dir, "pres_abs_predictions", x), recursive = FALSE)
  result_list <- lapply(sp_dirs, function(y) {
    read.csv(file.path(y, list.files(y, pattern = "_tune_results.csv$"))) %>% 
      dplyr::slice(which.min(classif.ce)) %>% 
      mutate(model = basename(y)) %>% 
      dplyr::select(model, classif.ce)
  }) %>% do.call(rbind, .) %>% 
    dplyr::mutate(species = x) %>% 
    dplyr::arrange(classif.ce)
}) %>% do.call(rbind, .)

write.csv(best_model_sets, file.path(
  output_dir, "pres_abs_predictions", "model_performance_index.csv"), 
  row.names = FALSE)

```

