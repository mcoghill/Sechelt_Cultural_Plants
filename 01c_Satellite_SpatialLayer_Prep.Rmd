---
title: "Satellite Derived Covariates Prep"
author: "Matt Coghill"
script author: "Matt Coghill"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Format sentinel dataset

Once the data has been downloaded, the layers are clipped to a template raster (as selected), resampled to match the extent and resolution and renamed to enable spectral indicies to be calculated. 



This document is going to be used to pull in relevant satellite layers for analysis. This is heavily adapted from the Hackathon in Prince George (https://github.com/bcgov-datasci-labs/BCForestNonForestPEM/blob/master/01_Load_Sentinel.R) and from conversations I had with Tom Hengl regarding satellite imagery. I have provided functions for downloading cloud free medians of satellite bands as they span across a given time frame (ex: spring). This requires an interface to Google Earth Engine.

The first thing that will be done is load in the required packages. SAGA CMD is required here for spatial processing as well, so it is important that it is loaded here too.

```{r load library, echo = FALSE}

ls <- c("stars", "raster", "tools", "xml2", "RStoolbox", "reticulate", "terra",
        "googledrive", "tidyverse", "stringi", "rstudioapi", "foreach", "snow")
new_packages <- ls[!(ls %in% installed.packages()[, "Package"])]
if(length(new_packages))
  install.packages(new_packages)
lapply(ls[ls != "reticulate"], library, character.only = TRUE)[0]
rm(ls, new_packages)

source(file.path('_functions', 'get_saga.R'))
saga_cmd <- get_saga()

```

The following chunk should only need to be ran once. This is where I anticipate some problems to arise. The reticulate package relies on using the conda distribution of python in order to communicate with the google earth engine. The steps that need to be followed are simple but I could see some pitfalls which I will outline here:

0: There are issues that arise when the reticulate package is loaded and you try setting a new environment. In order to work around this, the package needs to be detached and unloaded, then once the PATH is properly set it can be reloaded: https://stackoverflow.com/a/58743111/13191100

1. You have to have conda installed. This may already be done on a given system, however if it is not then it will be installed. For some reason, even if it's already installed it sometimes says that it isn't, that's why there is a "try" function which will try to install it but throw an error if it is already installed.

2. After a successful installation, a new python environment needs to be created (conda_create), and that environment needs to be set to be used after that (use_condaenv). 

3. Next, the appropriate python packages will be downloaded and installed to your set conda environment. There should be no more need to restart your system in this case!

4. Finally, the earthengine api needs authentication from you, so the appropriate web pages will open and following your permission, you will be given a key to copy and paste into the terminal. Make sure you right click the key into the terminal window. That should be all to get this to work!

```{r reticulate package setup}
# NOTE: The way this is written allows for functionizing, perhaps as the name
# "conda_prep(env)", or something like that, where the "env" argument is a 
# character string for the environment name. Leaving this not functionized for
# dubugging purposes.

python_setup <- function(x) {
  if("reticulate" %in% (.packages())) detach("package:reticulate", unload = TRUE)
  session_py_path <- file.path(reticulate::miniconda_path(), "envs", x)
  Sys.setenv(RETICULATE_PYTHON_ENV = x)
  Sys.setenv(RETICULATE_PYTHON = session_py_path)
  
  library(reticulate)
  # Install miniconda if it isn't already installed
  if(!py_available()) try(install_miniconda())
  use_python(miniconda_path())
  
  # Use the defined conda environment (x), create it if necessary
  conda_envs <- conda_list()
  if(!x %in% conda_envs$name) {
    
    # Create a conda environment to be used in this R session
    conda_create(envname = x)
    use_condaenv(x, required = TRUE)
    
    # Install conda packages that will be used here
    conda_install(envname = x,
                  packages = c("numpy", "pandas", "earthengine-api"),
                  forge = TRUE,
                  pip = TRUE,
                  conda = "auto")
    auth <- TRUE
    
  } else {
    # If conda environment exists, make sure the required python packages
    # are also installed, install missing packages where necessary
    message("Environment exists, checking for missing packages")
    use_condaenv(x, required = TRUE)
    packages <- character()
    if(!py_module_available("numpy"))  packages <- c(packages, "numpy")
    if(!py_module_available("pandas")) packages <- c(packages, "pandas")
    if(!py_module_available("ee")) {
      packages <- c(packages, "earthengine-api")
      auth <- TRUE
    } else auth <- FALSE
    
    if(length(packages)) {
      conda_install(envname = x,
                    packages = packages,
                    forge = TRUE,
                    pip = TRUE,
                    conda = "auto")
    }
  }
  
  # Authenticate GEE, will open browswer and you will copy and paste
  # an authentication key into the terminal. RIGHT CLICK TO PASTE KEY
  if(auth) {
    term_id <- terminalCreate()
    if(Sys.info()[["sysname"]] %in% c("Linux", "Darwin")) {
      cmd_path <- file.path(session_py_path, "bin")
      terminalSend(term_id, paste0(cmd_path, "/earthengine authenticate\r"))
      
    } else if(Sys.info()[["sysname"]] == "Windows") {
    terminalSend(term_id, "earthengine authenticate\r")
    }
    Sys.sleep(5)
    while(terminalBusy(term_id)) {
      Sys.sleep(0.5)
    }
    terminalKill(term_id)
  }
  return(invisible())
}

env <- "sentinel_sechelt"
python_setup(env)
```

Here, we can load some local directories and file paths. SAGA will be used to process band images (reprojecting and clipping to an AOI) so it is necessary to have it installed on your system.

```{r Set Directories, message=FALSE, warning=FALSE}

# Define study area folder
AOI <- "Sechelt"
AOI_dir <- file.path(".", paste0(AOI, "_AOI"))
AOI_epsg <- 3005
AOI_res <- c(4, 25)

# Define existing files and paths
map_res <- c(paste0(AOI_res, "m"), "25m_TRIM")
AOI_shapefile <- file.path(AOI_dir, "0_raw_inputs", "base_layers", map_res, "aoi.gpkg")
dem_hi_res <- file.path(AOI_dir, "1_map_inputs", "covariates", paste0(min(AOI_res), "m"), "dem.tif")
dem_list <- grep("1m", list.files(file.path(AOI_dir, "1_map_inputs", "covariates"), 
                                   pattern = "dem.tif", full.names = TRUE, recursive = TRUE), 
                  value = TRUE, invert = TRUE)


# Define path for file processing (doesn't have to exist)
raw_path <- file.path(AOI_dir, "0_raw_inputs", "satellite_layers")

```

The chunk below is provides the first of two major functions in this script. In this case, get_sentinel_ee() is used to download cloud free processed images from Google Earth Engine to your machine. The function needs an AOI input as an sf object, an ouptut EPSG code for transforming if necessary, a template raster which helps to determine the maximum download size, the date ranges provided as a table (id, from, to), the name of the Google Drive folder for downloading the files (a subfolder will be created within this folder for each of the date ranges specified), and a download folder to your PC.

This function requires that you have a google earth engine account created using a valid GMail account: https://code.earthengine.google.com/#

First, you must "initialize" the earth engine environment. This will open your web browser to a couple of pages asking for permission to write to your google drive folders. In the end, you will be given a key to copy and paste into a popup window in this R session, and initializaiton should be complete. Note that in the end the files written to Google Drive should not be very large, likely less than 500 Mb total, so that would be a good amount of available space to have on hand. It would also be possible to script automatic deletion of files after they are downloaded as well.

Next, provide the AOI shape as either an sf or sfc object. Note: It's a good idea to buffer the AOI in order to capture the edge effects in processing.

You need to create a dataframe with three columns: The first is an ID column, which will be used for creating subfolders in your downloads folder later. The second column is a start date column, and the third is an end date column. The example given here separates the dates by season; however, you can use as many or as little as you wish.

Finally the function is ran. You should specify a drive_folder for where outputs will be stored to on Google Drive as well as a download folder for when files are downloaded locally. The function takes sentinel 2 images from a specified date range (ex: winter), performs a cloud masking function to remove clouds from an image stack, and then calculates the median across that date range. The final image is clipped to your AOI, reprojected in BC Albers, and then saved to your google drive folder. Lastly, the image is downloaded locally to your machine where you specify.

```{r Satellite Download}
# This is a new function, allowing users to process Sentinel 2 bands in an area 
# over the course of a given time frame. It harnesses the computational power of 
# Google Earth Engine, making the computations much faster than it would be 
# locally This is now the recommended function.
get_sentinel_ee <- function(
  aoi = NULL, 
  out_epsg = NULL,
  template_raster = NULL, 
  date_ranges = NULL, 
  drive_folder = NULL, 
  download_folder = NULL) 
  {
  # Perform checks of function inputs
  if(!any(class(aoi) %in% c("sf", "sfc", "sfg")) || is.null(aoi)) {
    stop("\rError: You must specify an AOI as an sf, sfc, or sfg object")
    
  } else if(any(class(aoi) %in% c("sf", "sfc"))) {
    if(st_crs(aoi) != st_crs(4326)) aoi <- st_transform(aoi, 4326)
    
  } else if(any(class(aoi) %in% "sfg")) {
    aoi <- st_geometry(aoi) %>% st_set_crs(4326)
  }
  ee_geom <- as.numeric(paste(t(st_coordinates(aoi)[, c("X", "Y")])))
  ee_geom <- ee$Geometry$Polygon(coords = ee_geom)
  
  if(is.null(template_raster) || 
     !class(template_raster) %in% c("RasterLayer", "character")) {
    stop(
    "\rError: You must define the template_raster variable as either a 
    \r'RasterLayer' object, or a character string file path to a raster image"
    )
    
  } else if(class(template_raster) == "character") {
    template_raster <- raster(template_raster)
  }
  
  if(is.null(date_ranges) || !class(date_ranges) %in% "data.frame") {
    stop(
      "\rError: You must supply a data.frame with three columns:  
      \r  1: An ID column; 
      \r  2: A column of start dates; and 
      \r  3: A column of end dates.
      \rDates must be supplied as a character vector with the format 'YYYY-MM-DD'"
    )
  }
  
  if(is.null(drive_folder)) {
    drive_folder <- "Sentinel2"
  }
  
  if(is.null(download_folder) || !class(download_folder) %in% "character") {
    stop(
      "\rYou must supply an output directory for the files to be downloaded to"
    )
  }
  
  # Create a cloud masking function which will run in GEE
  cloud_mask <- function(image) {
    qa <- image$select("QA60")
    cloudBitMask <- bitwShiftL(1, 10)
    cirrusBitMask <- bitwShiftL(1, 11)
    mask <- qa$bitwiseAnd(cloudBitMask)$eq(0)$
      And(qa$bitwiseAnd(cirrusBitMask)$eq(0))
    image <- image$updateMask(mask)$divide(10000L)$
      select("B.*")$
      copyProperties(image, list("system:time_start"))
  }
  
  # Create the parent folder for the seasonal exports in your Google Drive folder
  try(drive_mkdir(drive_folder, path = "~", overwrite = FALSE), silent = TRUE)
  
  # Create a dataframe of Sentinel 2 band names and their associated resolutions
  bands <- data.frame(
    band = c("B1", "B2", "B3", "B4", "B5", "B6", 
             "B7", "B8", "B9", "B11", "B12", "B8A"), 
    new_name = c("b01", "b02", "b03", "b04", "b05", "b06", 
                 "b07", "b08", "b09", "b11", "b12", "b8A"),
    res = c(60, 10, 10, 10, 20, 20, 20, 10, 60, 20, 20, 20), 
    stringsAsFactors = FALSE)
  
  for(i in 1:nrow(date_ranges)) {
    date_id <- date_ranges[i, 1]
    message(paste0("\rStarting processing of ", date_id, " dates"))
    
    # Create the folder for the seasonal exports in your Google Drive folder
    drive_mkdir(date_id, path = "Sentinel2", overwrite = TRUE)
    
    # Create the folder for the seasonal downloads in your local folder
    out_dir <- file.path(download_folder, date_id)
    dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
    
    # Perform filtering operations in GEE
    sen <- ee$ImageCollection("COPERNICUS/S2_SR")$
      filterBounds(ee_geom)$
      filterDate(ee$Date(date_ranges[i, 2]), ee$Date(date_ranges[i, 3]))$
      filter(ee$Filter$lt("CLOUDY_PIXEL_PERCENTAGE", 20))$
      map(cloud_mask)
    
    # Take the median and clip the bands
    composite <- sen$median()
    comp_clip <- composite$clip(ee_geom)
    
    # Loop through to reproject and save each band
    for(j in 1:nrow(bands)) {
      task_img <- ee$batch$Export$image$toDrive(
        image = comp_clip$select(list(bands$band[j]))$
          reproject(paste0("EPSG:", out_epsg), NULL, bands$res[j]),
        folder = drive_get(paste0("Sentinel2/", date_id))$name,
        maxPixels = ncell(raster(template_raster)) * 2,
        fileNamePrefix = bands$new_name[j]
      )
      
      # Save the bands to google drive and download them
      task_img$start()
      while(task_img$active()) {
        print(sprintf("Polling for task (id: %s).", task_img$id))
        Sys.sleep(5)
      }
      print(sprintf("State: %s", task_img$status()$state))
      img <- drive_download(
        file = file.path(drive_folder, date_id, paste0(bands$new_name[j], ".tif")), 
        path = file.path(out_dir, paste0(bands$new_name[j], ".tif")), 
        overwrite = TRUE)
    }
  }
  return(list.files(download_folder, pattern = ".tif$", full.names = TRUE, 
                    recursive = TRUE))
}

```

# Generate satellite derivatives 

Running the get_sentinel_ee function should ouptput rasters with the desired CRS, so no reprojection of the satellite bands is necessary here.

The function bands_to_indices will take bands located in a given folder (satellite_files), pan sharpen the lower resolution bands, reproject and clip them to a given raster (reference_raster), and outputs a raster stack of indices which can be optionally saved to the main covariates folder. The option remove_index can be used if you don't want a particular index in your results (ex: EVI2 seems to generate large areas of no data).

Finally, these reprojected and masked files are used in the processing of vegetation and soil indices. Here, the RStoolbox package is being used to generate these indices all at once. This is not meant to be a comprehensive list of which indices should be used for the PEM project, however I think it provides a solid base for thinking of which indices to include. Some documentation:

https://bleutner.github.io/RStoolbox/rstbx-docu/spectralIndices.html
https://pro.arcgis.com/en/pro-app/help/data/imagery/indices-gallery.htm
https://www.usgs.gov/land-resources/nli/landsat/landsat-surface-reflectance-derived-spectral-indices

You might notice that not all of the indices from the ArcGIS and USGS websites are included in this package. As mentioned, the RStoolbox is not meant to represent the "be all and end all" of defining which indices to use. Some may not be appropriate to use here, however the package makes it really easy to generate those indices quite quickly.

```{r Convert raster bands to satellite indices}
# This function will take downloaded satellite images, transorm them, and output 
# multiple satellite image indices as a raster stack.
bands_to_indices <- function(
  reference_raster = NULL, 
  satellite_files = NULL, 
  output_path = NULL, 
  remove_index = NULL, 
  saga_cmd = NULL) 
  {
  
  # Perform input checks
  if(is.null(reference_raster) || 
     !class(reference_raster) %in% c("RasterLayer", "character")) {
    stop("\rError: You must specify a file path to a raster image")
  } else if(class(reference_raster) == "RasterLayer") {
    reference_raster <- reference_raster@file@name
  }
  
  if(is.null(satellite_files) || !is.character(satellite_files)) {
    stop(
      "\rError: You must supply a character vector of file paths to satellite 
      \rraster images"
    )
  }
  
  process_path <- file.path(dirname(dirname(dirname(satellite_files[1]))), "2_reproject")
  
  dir.create(process_path, recursive = TRUE, showWarnings = FALSE)
  ref <- rast(reference_raster)
  
  #############################################################################
  
  ## Pan sharpening testing: sentinel 2 doesn't have a pan sharpening band, but
  # it might be possible to use band 8 or the mean of bands 2, 3, 4, and 8:
  #https://www.mdpi.com/2072-4292/8/4/354/htm#B34-remotesensing-08-00354
  #https://www.researchgate.net/publication/323933204_Sentinel-2_Pan_Sharpening_-_Comparative_Analysis
  
  res_10 <- rast(satellite_files[sapply(satellite_files, function(x) 
    res(rast(x))[1], simplify = TRUE) %>% 
      grep(pattern = 10, value = FALSE)])
  res_20 <- stack(satellite_files[sapply(satellite_files, function(x) 
    res(raster(x))[1], simplify = TRUE) %>% 
      grep(pattern = 20, value = FALSE)])
  
  # Band 8 only as pan band:
  # pan <- raster(grep("b08", satellite_files, value = TRUE))
  
  # Mean of bands 2, 3, 4, and 8 as pan band, and convert to raster object:
  pan <- mean(res_10, na.rm = TRUE) %>% raster()
  res_10 <- stack(res_10@ptr$filenames)
  
  cat("\rApplying pan sharpening to low resolution bands")
  
  satellite_stack <- stack(
    res_10, panSharpen(res_20, pan = pan, method = "pca", norm = FALSE)
  )
  names(satellite_stack) <- gsub("_pan$", "", names(satellite_stack))
  
  # Change band names to be more descriptive
  band_lookup <- tribble(
    ~band_no, ~band_name,
    "b01", "ultrablue", "b02", "blue", "b03", "green", "b04", "red", 
    "b05", "redEdge1", "b06", "redEdge2", "b07", "redEdge3", "b08", "nir",
    "b09", "wv", "b11", "swir2", "b12", "swir3", "b8A", "narrow_nir"
  )
  
  for(i in 1:nlayers(satellite_stack)) {
    if(any(grepl(names(satellite_stack)[i], band_lookup$band_no))) {
      names(satellite_stack)[i] <- band_lookup$band_name[
        which(band_lookup$band_no %in% names(satellite_stack)[i])
        ]
    }
  }
  
  # Produce vegetation indices from band layers
  satellite_indices <- spectralIndices(
    img = satellite_stack, 
    blue = "blue", green = "green", red = "red", nir = "nir", 
    redEdge1 = "redEdge1", redEdge2 = "redEdge2", redEdge3 = "redEdge3", 
    swir2 = "swir2", swir3 = "swir3", 
    scaleFactor = 1, 
    coefs = list(swir2ccc = satellite_stack$swir2@data@min, 
                 swir2coc = satellite_stack$swir2@data@max)
  )
  
  if(!is.null(remove_index)) {
    satellite_indices <- dropLayer(satellite_indices, remove_index)
  }
  
  # MOVE CODE TO SAGA GIS FOR FURTHER PROCESSING
  for(i in names(satellite_indices)) {
    writeRaster(
      subset(satellite_indices, i), 
      file.path(process_path, paste0(i, ".tif")), 
      overwrite = TRUE)
  }
  cat("\rMasking and writing ouputs")
  
  
  ##################
  saga_ver <- system2(saga_cmd, "-v", stdout = TRUE)
  saga_ver <- unlist(regmatches(saga_ver, regexec("Version:\\s*(.*?)\\s*\\(", saga_ver)))[2]
  
  tool_list <- list(
    header = paste0(
      "<?xml version='1.0' encoding='UTF-8'?>
          <toolchain saga-version='", saga_ver, "'>
          <group>toolchains</group>
          <identifier>trans_mask</identifier>
          <name>Transform and mask (one step)</name>
          <description>
            Common DEM derivatives in SAGA GIS
          </description>
        
          <parameters>
            <option varname='GRID_SYSTEM' type='grid_system'>
              <name>Grid System</name>
            </option>
            <input varname='dem' type='grid' parent='GRID_SYSTEM'>
                <name>DEM</name>
            </input>
            <input varname='sat' type='grid_list'>
                <name>Satellite variables</name>
            </input>
          </parameters>
          <tools>", sep = "\n"
    ),
    transform = paste0(
      "<tool library='grid_tools' tool='0' name='Resampling'>
        <input id='INPUT'>sat</input>
        <output id='OUTPUT'>sat_rep</output>
        <option id='KEEP_TYPE'>false</option>
        <option id='SCALE_DOWN'>3</option>
        <option id='TARGET_DEFINITION'>1</option>
        <input id='TARGET_TEMPLATE'>dem</input>
      </tool>"
    ),
    reps = foreach(grid = 1:length(names(satellite_indices)), .combine = paste) %do% {
      select = paste0(
        "<tool library='grid_tools' tool='32' name='Select Grid from List'>
        <input id='GRIDS'>sat_rep</input>
        <output id='GRID'>", names(satellite_indices)[grid], "</output>
        <option id='INDEX'>", grid - 1, "</option>
      </tool>"
      )
      mask = paste0(
        "<tool library='grid_tools' tool='24' name='Grid Masking'>
        <input id='GRID'>", names(satellite_indices)[grid], "</input>
        <input id='MASK'>dem</input>
        <output id='MASKED'>", paste(names(satellite_indices)[grid], "[masked]"), "</output>
      </tool>"
      )
      export = paste0(
        "<tool library='io_gdal' tool='2' name='Export GeoTIFF'>
        <input id='GRIDS'>", paste(names(satellite_indices)[grid], "[masked]"), "</input>
        <option id='FILE'>", file.path(
        process_path,
        tolower(paste0("sentinel2_", 
                       names(satellite_indices)[grid], "_", 
                       basename(dirname(satellite_files[1])), ".tif"))), "</option>
      </tool>"
      )
      return(paste(select, mask, export, collapse = " ", sep = "\n"))}, 
    footer = paste0(
      "</tools>
      </toolchain>"
    )
  )
  call <- paste0(tool_list, sep = "\n", collapse = " ")
  
  # Determine the toolchain directory based on your system
  xml_dir <- ifelse(
    Sys.info()[["sysname"]] == "Windows", 
    file.path(dirname(saga_cmd), "tools", "toolchains", "trans_mask.xml"), 
    file.path(dirname(dirname(saga_cmd)), "share", "saga", 
              "toolchains", "trans_mask.xml")
  )
  write_xml(read_xml(call), xml_dir)
  sys_cmd <- paste("toolchains trans_mask",
                   "-dem", reference_raster,
                   "-sat", paste(list.files(file.path(process_path), 
                                      pattern = paste0(names(satellite_indices), ".tif", collapse = "|"),
                                      full.names = TRUE), collapse = ";")
                   )
  system2(saga_cmd, sys_cmd)
  
  # Projections are correct, but in case the proj4string is incorrect:
  sat_indices <- rast(file.path(
        process_path,
        tolower(paste0("sentinel2_", 
                       names(satellite_indices), "_", 
                       basename(dirname(satellite_files[1])), ".tif"))))
  
  crs(sat_indices) <- crs(ref)
  for(i in names(sat_indices)) {
    writeRaster(subset(sat_indices, i),
                file.path(output_path, paste0(i, ".tif")), 
                overwrite = TRUE)
  }
  
  #####################
  
  # Generare an RGB for background image
  # RGB <- subset(satellite_stack, c("red", "green", "blue"))
  # writeRaster(
  #   RGB,
  #   file.path(
  #     process_path,
  #     paste0("sentinel2_RGB_", basename(dirname(satellite_files[1])), ".tif")),
  #   overwrite = TRUE)
  
  return(invisible())
}

```

Finally, we just need to run the function. I've included examples for processing this when a single scene is downloaded, and for when composite images from google earth engine have been downloaded

```{r run functions}
# Initialize the google earth engine
ee <- import("ee")
ee$Initialize()

# Create a bounding box of the AOI. Needs to be transformed to EPSG 4326
AOI_bbox <- st_read(AOI_shapefile[1], quiet = TRUE) %>%
  st_bbox() %>%
  st_as_sfc() %>%
  st_buffer(dist = 250, joinStyle = "MITRE") %>%
  st_transform(4326)

# Provide a data frame of dates to collect data between. The longer the data
# frame, the longer it will take to process and download your dataset.
seasons_df <- data.frame(
  season = c("2019"),
  start = c("2019-01-01"),
  end = c("2019-12-31"),
  stringsAsFactors = FALSE
)

# Authorize R to view/edit your Google Drive folders
term <- rstudioapi::terminalCreate()
rstudioapi::terminalSend(term, "R\r")
rstudioapi::terminalSend(term, "googledrive::drive_auth()\r")
rstudioapi::terminalKill(term)

# Run get_sentinel_ee function to process and download satellite images
ee_download <- get_sentinel_ee(
  aoi = AOI_bbox,
  out_epsg = AOI_epsg,
  template_raster = dem_hi_res,
  date_ranges = seasons_df,
  drive_folder = "Sentinel2",
  download_folder = file.path(raw_path, "1_download")
)

season_dirs <- dir(file.path(raw_path, "1_download"), 
                   full.names = TRUE)[dir(file.path(raw_path, "1_download"))
                                      %in% seasons_df$season]

# Run the bands_to_indices function to produce satellite indices for each 
# of the date ranges
for(i in season_dirs) {
  for(dem in dem_list) {
    sat_indices <- bands_to_indices(
      reference_raster = dem, 
      satellite_files = list.files(i, full.names = TRUE),
      output_path = dirname(dem), 
      remove_index = c("EVI2"), 
      saga_cmd = saga_cmd
    )
  }
}

```

##Water from NDWI layer
According to multiple sources, values of > 0 for the MNDWI layer indicate the presence of a water body. This process can be easily scripted to detect the location of water across a landscape and can be used to compare to that of the water layer downloaded as shapes from the bcdata package

https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018RG000598

https://www.researchgate.net/profile/Hanqiu_XU/publication/232724072_Modification_of_Normalized_Difference_Water_Index_NDWI_to_Enhance_Open_Water_Features_in_Remotely_Sensed_Imagery/links/5c9aee13299bf1116949a345/Modification-of-Normalized-Difference-Water-Index-NDWI-to-Enhance-Open-Water-Features-in-Remotely-Sensed-Imagery.pdf

```{r find water from MNDWI}
# Looking at all of the mndwi files produced, the best one to use is going to be
# the one from the summer time frame
for(i in dem_list) {
  if(file.exists(file.path(dirname(i), "sentinel2_mndwi_summer.tif"))) {
    mndwi_summer <- rast(file.path(dirname(i), "sentinel2_mndwi_summer.tif"))
    
    # Reclassify raster values
    water <- classify(mndwi_summer, matrix(c(-Inf, 0, NA, 
                                             0, Inf, 1), 
                                           ncol = 3, byrow = TRUE))
    
    # Raster to sf conversion via stars package
    water_sf <- st_as_stars(raster(water)) %>%
      st_as_sf(as_points = FALSE, merge = TRUE, na.rm = TRUE, use_integer = TRUE) %>%
      st_geometry() %>% 
      st_union()
    
    st_write(
      water_sf, 
      file.path(AOI_dir, "0_raw_inputs", "base_layers", basename(dirname(i)), "water_mndwi.gpkg"), 
      delete_layer = TRUE)
  }
}

```
