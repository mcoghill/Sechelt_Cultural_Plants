---
title: "Download base data from BC data catalogue"
author: "Matt Coghill"
script author: "Matt Coghill"
output: html_document
---

The purpose of this script is to download the relevant spatial data for BEC zones, VRI, TEM, waterbodies and the road network. Data is downloaded directly from the [BC Data Catalogue](https://catalogue.data.gov.bc.ca/dataset?download_audience=Public) using the [bcdata](https://github.com/bcgov/bcdata) package.

```{r packages, include=FALSE}

ls <- c("bcdata", "bcmaps", "tidyverse", "terra", "foreach", "doParallel", "raster")
github_ls <- c("bcmapsdata")
new_packages <- ls[!(ls %in% installed.packages()[, "Package"])]
github_new_packages <- github_ls[!(github_ls %in% installed.packages()[, "Package"])]
if(length(new_packages))
  install.packages(new_packages)
if(length(github_new_packages))
  install.packages('bcmapsdata', repos = 'https://bcgov.github.io/drat/')
if(compareVersion(packageDescription("raster")$Version, "3.3-14") < 0) 
  devtools::install_github("rspatial/raster")
if(compareVersion(packageDescription("terra")$Version, "0.8-5") < 0) 
  install.packages("rspatial/terra")
ls <- c(ls, github_ls)
lapply(ls, library, character.only = TRUE)[0]
rm(ls, github_ls, new_packages, github_new_packages)

```

### Datasets to download 

* BEC - [Biogeoclimatic Ecosystems Classification](https://catalogue.data.gov.bc.ca/dataset/bec-map) are used to define and/or select specific "subzones" within a defined study area. 

* Vegetation Resource Inventory (VRI) - This layer includes a variety of vegetation measure, including cutblock age, TEM data and ..... Detailed data standards can be found [here](https://www2.gov.bc.ca/gov/content/industry/forestry/managing-our-forest-resources/forest-inventory/data-management-and-access/vri-data-standards).  

* Freshwater Atlas -  The atlas is separated into the different types of waterbodies (lakes, rivers, wetlands, streams, man made, etc.), which requires a seperate download per type. Alternatively a single combined layer can be downloaded but is limited to linear data type. A parameter within the function can be set to "polygon" (the default option) or "linear".  

* Road network - In previous works, the raw road network was found to be too detailed. The raw road network is filtered to only keep named roads, and then the up to date FSR layer is downloaded and merged with the filtered road network to produce a really good representation of where roads are actually located on the landscape.

* Terrestrial Ecosystem Map (TEM) - If a study area contains a TEM from a previous project, it is downloaded here. A TEM is similar to a PEM, though it is a more expert based approach, whereas a PEM uses machine learning to find the site series.

* Cutblocks - This augments the VRI layer to highlight cutblock polygons in the area which may be useful for determining where/where not to sample




## Work-flow

This script relies on having a spatial file (AOI.gpkg) defining the study area (area of interest - AOI). This will need to be created from your DEM file.

Where a subset of the study area is being used (ie. by subzone), a character string is used to define the subzone(s) of interest and filter only the areas you specify. The default value (NULL) will include all subzones. 

Finally, it is assumed that since you have an AOI shapefile that it was produced in the initial LiDAR script, implying that some raster files were produced (height metrics and dem). If a subzone filter was applied, you may want to mask your raster to the new AOI shape so that they are excluded from further analysis.

```{r Parameters}

AOI <- "Sechelt"
AOI_dir <- file.path(".", paste0(AOI, "_AOI"))
shp_dir <- file.path(AOI_dir, "0_raw_inputs", "base_layers")
cov_dir <- file.path(AOI_dir, "1_map_inputs", "covariates")

```

In order to get accurate polygon edges for each raster resolution, they need to be individually created and saved. The polygonization of a raster will take place using the terra package. It first replaces values in a raster with 0's, and then polygonizes the "grid classes" (of which there would only be a single class, 0). The output shape is saved as a geopackage through the use of the sf package (terra doesn't currently support geopackage saving yet).

```{r Raster to polygon}

dem_files <- list.files(cov_dir, pattern = "dem.tif", full.names = TRUE, recursive = TRUE)

for(i in dem_files) {
  shp_subdir <- file.path(shp_dir, basename(dirname(i)))
  dir.create(shp_subdir, recursive = TRUE, showWarnings = FALSE)
  
  dem <- rast(i) * 0
  dem_shp <- as.polygons(dem, trunc = TRUE, dissolve = TRUE, values = FALSE, 
                         extent = FALSE, crs = crs(dem)) %>% 
    as("Spatial") %>% 
    st_as_sfc() %>% 
    st_set_crs(crs(dem))
  st_write(dem_shp, file.path(shp_subdir, "aoi.gpkg"), delete_dsn = TRUE, quiet = TRUE)
}

```

A single function is used to download BEC zone info, VRI shapes, TEM shapes (if applicable), water bodies, and roads all in one go. Each is clipped to the extent of the study area at each resolution, though this may not be very efficient. 

```{r Function}

get_bc_shapes <- function(in_aoi, 
  out_path, 
  epsg = 3005) 
  {
  
  #### Input checks
  ## in_aoi should be an sf object or file path
  if(missing(in_aoi)) stop("\nYou must provide a valid AOI either as a shape or a file path to a shape")
  if(class(in_aoi) %in% "sf") { study_area <- in_aoi
  } else if(is.character(in_aoi)) { study_area <- sf::st_read(in_aoi, quiet = TRUE)
  } else stop("'in_aoi' requires an sf object input")
  
  if(missing(out_path) && is.character(in_aoi)) {
    out_path <- dirname(in_aoi)
  } else stop("'out_path' is an invalid file path string")
  
  # Create function to remove incorrect geometries from shapes due to clipping
  st_force_poly <- function(sf) {
    if(!all(sf::st_geometry_type(sf) %in% c("POLYGON", "MULTIPOLYGON"))) {
      bec_sfc <- sf::st_geometry(sf) %>% 
        lapply(function(x) {
          if(sf::st_geometry_type(x) == "GEOMETRYCOLLECTION") {
            extr <- sf::st_collection_extract(x, type = "POLYGON", warn = FALSE)
            if(length(extr) > 1) {
              sf::st_multipolygon(extr) 
              } else sf::st_polygon(extr)
          } else if(!sf::st_geometry_type(x) %in% c("POLYGON", "MULTIPOLYGON")) {
            x <- NULL
          } else x
        }) %>% sf::st_sfc(crs = epsg)
      st_geometry(sf) <- bec_sfc
    }
    return(sf)
  }
  
  #### Function script
  # Set or transform CRS of input AOI if not provided
  start <- Sys.time()
  if(is.na(sf::st_crs(study_area)$proj4string)) {
    message(paste("\nNo CRS detected for in_aoi, setting to EPSG", epsg))
    study_area <- sf::st_set_crs(study_area, epsg)
    
  } else if(sf::st_crs(study_area) != sf::st_crs(epsg)) {
    study_area <- sf::st_transform(study_area, epsg)
  }
  study_area <- sf::st_make_valid(study_area) %>% 
    sf::st_geometry()
  
  # Adjust max download size based on AOI
  options(bcdata.max_geom_pred_size = as.numeric(st_area(study_area)) + 10)
    
  suppressMessages({
    # Download BEC, transform if necessary, and clip to AOI
    cat("\nDownloading BEC layer")
    bec_sf <- bcmaps::bec(class = "sf")
    if(sf::st_crs(bec_sf) != sf::st_crs(study_area)) bec_sf <- sf::st_transform(bec_sf, epsg)
    bec_sf <- sf::st_set_agr(bec_sf, "constant") %>% 
      sf::st_intersection(study_area) %>%
      dplyr::group_by(MAP_LABEL) %>% 
      dplyr::summarise(.groups = "drop") %>% 
      st_force_poly()
    
    # Download TEM
    cat("\nDownloading TEM layer")
    tem <- bcdata::bcdc_query_geodata("0a83163b-a62f-4ce6-a9a1-21c228b0c0a3", crs = epsg) %>%
      bcdata::filter(bcdata::BBOX(sf::st_bbox(study_area), crs = epsg)) %>%
      bcdata::collect() %>% 
      sf::st_set_agr("constant") %>% 
      {if(nrow(.) > 0) {
        sf::st_intersection(., study_area) %>% st_force_poly()
      } else .}
    
    sf::st_write(tem, file.path(out_path, "tem.gpkg"), 
                 delete_dsn = TRUE, quiet = TRUE)
    
    # Adjust BEC subzone lines to match TEM since TEM is higher accuracy
    if(nrow(tem) > 0 && all(unique(bec_sf$MAP_LABEL) %in% unique(tem$BIOGEOCLIMATIC_LBL))) {
      bec_fix <- tem %>% dplyr::select(BIOGEOCLIMATIC_LBL) %>% 
        dplyr::group_by(BIOGEOCLIMATIC_LBL) %>% 
        dplyr::summarise(.groups = "drop") %>% st_force_poly()
      if(any(is.na(bec_fix$BIOGEOCLIMATIC_LBL))) {
        bec_sf <- sf::st_set_agr(bec_fix, "constant") %>% 
          sf::st_intersection(
            sf::st_set_agr(bec_sf[, "MAP_LABEL"], "constant")) %>% 
          dplyr::mutate(BIOGEOCLIMATIC_LBL = ifelse(
            is.na(BIOGEOCLIMATIC_LBL), MAP_LABEL, BIOGEOCLIMATIC_LBL)) %>% 
          dplyr::group_by(BIOGEOCLIMATIC_LBL) %>% 
          dplyr::summarise(.groups = "drop") %>% 
          dplyr::rename(MAP_LABEL = BIOGEOCLIMATIC_LBL) %>% st_force_poly()
      } else bec_sf <- dplyr::rename(bec_fix, MAP_LABEL = BIOGEOCLIMATIC_LBL)
    }
    
    sf::st_write(bec_sf, file.path(out_path, "bec.gpkg"), delete_dsn = TRUE, quiet = TRUE)
    
    # Download VRI
    cat("\nDownloading VRI layer")
    vri <- bcdata::bcdc_query_geodata("2ebb35d8-c82f-4a17-9c96-612ac3532d55", crs = epsg) %>% 
      bcdata::filter(BBOX(st_bbox(study_area), crs = epsg)) %>%
      bcdata::collect() %>% 
      sf::st_set_agr("constant") %>% 
      {if(nrow(.) > 0) {
        sf::st_intersection(., study_area) %>% st_force_poly() 
      } else .}
    
    sf::st_write(vri, file.path(out_path, "vri_full.gpkg"), delete_dsn = TRUE, 
                 quiet = TRUE)
    sf::st_write(dplyr::select(vri, "BCLCS_LEVEL_2"), 
                 file.path(out_path, "vri_trees.gpkg"), # Treed sites
                 delete_dsn = TRUE, quiet = TRUE)
    
    # Download recent cutblocks layer
    # Uses date filter which filters cutblock ages less than 20 years, or 7305 days
    cat("\nDownloading cutblock layer")
    cutblocks <- bcdata::bcdc_query_geodata("b1b647a6-f271-42e0-9cd0-89ec24bce9f7", crs = epsg) %>% 
      bcdata::filter(BBOX(sf::st_bbox(study_area), crs = epsg)) %>%
      bcdata::collect() %>% 
      sf::st_set_agr("constant") %>% 
      {if(nrow(.) > 0) {
        sf::st_intersection(., study_area) %>% st_force_poly()
      } else .} %>% 
      mutate(DISTURBANCE_START_DATE = as.Date(DISTURBANCE_START_DATE),
             DISTURBANCE_END_DATE = as.Date(DISTURBANCE_END_DATE)) %>% 
      dplyr::filter(as.numeric(format(Sys.time(), "%Y")) - HARVEST_YEAR <= 20)
    
    sf::st_write(cutblocks, file.path(out_path, "young_cutblocks.gpkg"), 
             delete_dsn = TRUE, quiet = TRUE)
    
    # Download water layers, requires merging multiple layers
    cat("\nDownloading water layers")
    
    # Use foreach in parallel to efficiently download multiple water layers
    water_records <- c("cb1e3aba-d3fe-4de1-a2d4-b8b6650fb1f6", # lakes
                       "f7dac054-efbf-402f-ab62-6fc4b32a619e", # rivers
                       "93b413d8-1840-4770-9629-641d74bd1cc6") # wetlands
    
    cl <- parallel::makeCluster(min(parallel::detectCores(), length(water_records)))
    doParallel::registerDoParallel(cl)
    
    waterbodies <- foreach(
      i = water_records, .combine = rbind, .packages = c("tidyverse", "bcdata", "sf")) %dopar% {
        bcdata::bcdc_query_geodata(i, crs = epsg) %>%
          bcdata::filter(bcdata::BBOX(sf::st_bbox(study_area), crs = epsg)) %>%
          bcdata::collect() %>% 
          sf::st_set_agr("constant") %>% 
          {if(nrow(.) > 0) {
            sf::st_intersection(., study_area) %>% st_force_poly()
          } else NULL}
      }
    parallel::stopCluster(cl)
    
    sf::st_write(waterbodies, file.path(out_path, "water.gpkg"), 
             delete_dsn = TRUE, quiet = TRUE)
    
    # Download road network
    # The main road network layer has too many roads in it. Filter it down to only
    # include named roads and combine those with actual mapped FSR's
    cat("\nDownloading Road network")
    roads <- bcdata::bcdc_query_geodata("bb060417-b6e6-4548-b837-f9060d94743e", crs = epsg) %>% 
      bcdata::filter(
        bcdata::BBOX(sf::st_bbox(study_area), crs = epsg),
        ROAD_NAME_ID > 0) %>%
      bcdata::collect() %>% 
      dplyr::select(id, ROAD_NAME_FULL, FEATURE_LENGTH_M) %>% 
      dplyr::rename(NAME = ROAD_NAME_FULL)
    
    fsr <- bcdata::bcdc_query_geodata("9e5bfa62-2339-445e-bf67-81657180c682", crs = epsg) %>% 
      bcdata::filter(
        bcdata::BBOX(sf::st_bbox(study_area), crs = epsg),
        LIFE_CYCLE_STATUS_CODE == "ACTIVE") %>%
      bcdata::collect() %>% 
      dplyr::select(id, MAP_LABEL, FEATURE_LENGTH_M) %>% 
      dplyr::rename(NAME = MAP_LABEL)
    
    road_merge <- rbind(roads, fsr) %>% 
      sf::st_set_agr("constant") %>% 
      {if(nrow(.) > 0) {
        sf::st_intersection(., study_area) %>% 
          sf::st_cast("MULTILINESTRING")
      } else .}
    
    sf::st_write(road_merge, file.path(out_path, "road_network.gpkg"), 
             delete_dsn = TRUE, quiet = TRUE)
    
    # Download fire polygons
    cat("\nDownloading Fire areas")
    fire_records <- c("cdfc2d7b-c046-4bf0-90ac-4897232619e1", 
                      "22c7cb44-1463-48f7-8e47-88857f207702")
    
    cl <- parallel::makeCluster(min(parallel::detectCores(), length(fire_records)))
    doParallel::registerDoParallel(cl)
    
    fires <- foreach(
      i = fire_records, .combine = rbind, .packages = c("tidyverse", "bcdata", "sf")) %dopar% {
        bcdata::bcdc_query_geodata(i, crs = epsg) %>%
          bcdata::filter(bcdata::BBOX(sf::st_bbox(study_area), crs = epsg)) %>%
          bcdata::collect() %>% 
          sf::st_set_agr("constant") %>% 
          {if(nrow(.) > 0) {
            sf::st_intersection(., study_area) %>% 
              dplyr::select(id, FIRE_NUMBER, VERSION_NUMBER, FIRE_YEAR, 
                            FIRE_SIZE_HECTARES, LOAD_DATE) %>% 
              dplyr::filter(as.numeric(format(Sys.time(), "%Y")) - FIRE_YEAR <= 20) %>% 
              st_force_poly()
          } else NULL}
      }
    
    parallel::stopCluster(cl)
    sf::st_write(fires, file.path(out_path, "fires.gpkg"), 
             delete_dsn = TRUE, quiet = TRUE)
  })
  out <- list.files(out_path, pattern = ".gpkg", full.names = TRUE)
  return(out[start < file.mtime(out)])
}

```

We can define input AOI's at each resolution and run the function to save all of the downloaded files. If there are only some subzones of interest, the raster files can be updated to that extent here.

```{r Run Function}

# Define the input AOI files
in_aoi <- list.files(shp_dir, pattern = "aoi.gpkg", 
                     full.names = TRUE, recursive = TRUE)

# Run the function in a loop for multiple input AOI's (function will default
# out_path designation to the folder of in_aoi if in_aoi is a file path)
bc_shapes <- lapply(in_aoi, get_bc_shapes) %>% 
  magrittr::set_names(basename(dirname(in_aoi)))

```
