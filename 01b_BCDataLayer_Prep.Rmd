---
title: "Download base data from BC data catalogue"
author: "Matt Coghill"
script author: "Matt Coghill"
output: html_document
---

The purpose of this script is to download the relevant spatial data for BEC zones, VRI, TEM, waterbodies and the road network. Data is downloaded directly from the [BC Data Catalogue](https://catalogue.data.gov.bc.ca/dataset?download_audience=Public) using the [bcdata](https://github.com/bcgov/bcdata) package.

```{r packages, include=FALSE}

suppressMessages(suppressWarnings({
  ls <- c("bcdata", "bcmaps", "tidyverse", "terra", "future.apply", "raster")
  new_packages <- ls[!(ls %in% installed.packages()[, "Package"])]
  if(length(new_packages))
    install.packages(new_packages)
  if(compareVersion(packageDescription("raster")$Version, "3.3-14") < 0) 
    devtools::install_github("rspatial/raster")
  if(compareVersion(packageDescription("terra")$Version, "0.8-5") < 0) 
    install.packages("rspatial/terra")
  lapply(ls, library, character.only = TRUE)[0]
  rm(ls, new_packages)}))

```

### Datasets to download 

* BEC - [Biogeoclimatic Ecosystems Classification](https://catalogue.data.gov.bc.ca/dataset/bec-map) are used to define and/or select specific "subzones" within a defined study area. 

* Vegetation Resource Inventory (VRI) - This layer includes a variety of vegetation measure, including cutblock age, TEM data and ..... Detailed data standards can be found [here](https://www2.gov.bc.ca/gov/content/industry/forestry/managing-our-forest-resources/forest-inventory/data-management-and-access/vri-data-standards).  

* Freshwater Atlas -  The atlas is separated into the different types of waterbodies (lakes, rivers, wetlands, streams, man made, etc.), which requires a seperate download per type. Alternatively a single combined layer can be downloaded but is limited to linear data type. A parameter within the function can be set to "polygon" (the default option) or "linear".  

* Road network - In previous works, the raw road network was found to be too detailed. The raw road network is filtered to only keep named roads, and then the up to date FSR layer is downloaded and merged with the filtered road network to produce a really good representation of where roads are actually located on the landscape.

* Terrestrial Ecosystem Map (TEM) - If a study area contains a TEM from a previous project, it is downloaded here. A TEM is similar to a PEM, though it is a more expert based approach, whereas a PEM uses machine learning to find the site series.

* Cutblocks - This augments the VRI layer to highlight cutblock polygons in the area which may be useful for determining where/where not to sample




## Work-flow

This script relies on having a spatial file (AOI.gpkg) defining the study area (area of interest - AOI). This will need to be created from your DEM file.

Where a subset of the study area is being used (ie. by subzone), a character string is used to define the subzone(s) of interest and filter only the areas you specify. The default value (NULL) will include all subzones. 

Finally, it is assumed that since you have an AOI shapefile that it was produced in the initial LiDAR script, implying that some raster files were produced (height metrics and dem). If a subzone filter was applied, you may want to mask your raster to the new AOI shape so that they are excluded from further analysis.

```{r Parameters}

AOI <- "Sechelt"
AOI_dir <- file.path(".", paste0(AOI, "_AOI"))
shp_dir <- file.path(AOI_dir, "0_raw_inputs", "base_layers")
cov_dir <- file.path(AOI_dir, "1_map_inputs", "covariates")

```

In order to get accurate polygon edges for each raster resolution, they need to be individually created and saved. The polygonization of a raster will take place using the terra package. It first replaces values in a raster with 0's, and then polygonizes the "grid classes" (of which there would only be a single class, 0). The output shape is saved as a geopackage through the use of the sf package (terra doesn't currently support geopackage saving yet).

```{r Raster to polygon}

dem_files <- list.files(cov_dir, pattern = "dem.tif$", 
                        full.names = TRUE, recursive = TRUE)

for(i in dem_files) {
  shp_subdir <- file.path(shp_dir, basename(dirname(i)))
  dir.create(shp_subdir, recursive = TRUE, showWarnings = FALSE)
  
  dem <- rast(i) * 0
  dem_shp <- as.polygons(dem, trunc = TRUE, dissolve = TRUE, values = TRUE, 
                         extent = FALSE, crs = crs(dem)) %>% 
    as("Spatial") %>% 
    st_as_sfc() %>% 
    st_set_crs(crs(dem)) %>% 
    st_make_valid()
  st_write(dem_shp, file.path(shp_subdir, "aoi.gpkg"), 
           delete_dsn = TRUE, quiet = TRUE)
}

```

A single function is used to download BEC zone info, VRI shapes, TEM shapes (if applicable), water bodies, and roads all in one go. Each is clipped to the extent of the study area at each resolution, though this may not be very efficient. 

```{r Function}

get_bc_shapes <- function(in_aoi, out_path, epsg = 3005) {
  
  #### Input checks
  ## Restrict in_aoi to being an sf, sfc, or list of sf or sfc objects (polygons only)
  ## sfg objects not allowed since they have no CRS information
  ## STILL NEED CASE WHEN THERE ARE MULTIPLE OBJECTS, ex: an sf dataframe with 
  ## more than one row. Right now, this works when it is only a single row
  ## We only really want a single sfc polygon out, so maybe an st_combine call?
  if(missing(in_aoi)) stop("'in_aoi' is missing with no default")
  if(missing(out_path)) stop("'out_path' is missing with no default")
  if(length(out_path) > 1) stop("Only one file path allowed")
  if(!is.numeric(epsg)) stop("'epsg' is invalid, requires a numerical EPSG code")
  
  # Use list processing throughout. If not initially a list, make into one
  rand_name <- basename(tempfile())
  if(all(class(in_aoi) != "list")) 
    in_aoi <- list(in_aoi) %>% magrittr::set_names(rand_name)
  
  if(is.null(names(in_aoi))) stop("List elements must be named")
  
  # If all are sfc, easy peasy
  if(all(sapply(in_aoi, function(x) 
    any(class(x) %in% c("sfc_POLYGON", "sfc_MULTIPOLYGON"))))) {
    study_area <- in_aoi
    
    # If all are sf, fairly simple as well
  } else if(all(sapply(in_aoi, function(x)
    any(class(x) %in% "sf")))) {
    if(all(sapply(in_aoi, function(x) {
      any(class(st_geometry(x)) %in% c("sfc_POLYGON", "sfc_MULTIPOLYGON"))
    }))) {
      study_area <- lapply(in_aoi, st_geometry)
    } else stop("Not all listed sf features are of POLYGON or MULTIPOLYGON class")
    
    # If some are sfc and some are sf...
  } else if(all(sapply(in_aoi, function(x)
    any(class(x) %in% c("sf", "sfc_POLYGON", "sfc_MULTIPOLYGON"))))) {
    in_aoi_sfc <- Filter(function(x) 
      any(class(x) %in% c("sfc_POLYGON", "sfc_MULTIPOLYGON")), in_aoi)
    in_aoi_sf <- Filter(function(x) 
      any(class(x) %in% "sf"), in_aoi)
    if(all(sapply(in_aoi_sf, function(x) 
      any(class(st_geometry(x)) %in% c("sfc_POLYGON", "sfc_MULTIPOLYGON"))))) {
      study_area <- c(lapply(in_aoi_sf, st_geometry), in_aoi_sfc)
    } else stop("Not all listed sf features are of POLYGON or MULTIPOLYGON class")
  } else stop("Some list elements are not valid sf or sfc obects.")
  
  # Set out_path variable
  if(length(study_area) > 1 || names(study_area)[1] != rand_name) {
    out_path <- as.list(file.path(out_path, names(in_aoi))) %>% 
      magrittr::set_names(names(study_area))
  } else out_path <- as.list(out_path) %>% magrittr::set_names(names(study_area))
  sapply(out_path, dir.create, showWarnings = FALSE, recursive = TRUE)
  
  # Create function to remove incorrect geometries from shapes due to clipping
  st_force_poly <- function(sf) {
    if(!all(sf::st_geometry_type(sf) %in% c("POLYGON", "MULTIPOLYGON"))) {
      bec_sfc <- sf::st_geometry(sf) %>% 
        lapply(function(x) {
          if(sf::st_geometry_type(x) == "GEOMETRYCOLLECTION") {
            extr <- sf::st_collection_extract(x, type = "POLYGON", warn = FALSE)
            if(length(extr) > 1) {
              sf::st_multipolygon(extr) 
            } else sf::st_polygon(extr)
          } else if(!sf::st_geometry_type(x) %in% c("POLYGON", "MULTIPOLYGON")) {
            x <- NULL
          } else x
        }) %>% sf::st_sfc(crs = epsg)
      st_geometry(sf) <- bec_sfc
    }
    return(sf)
  }
  
  #### Function script
  # Set or transform CRS of input AOI if not provided
  study_area <- lapply(study_area, function(x) {
    if(is.na(sf::st_crs(x)$proj4string)) {
      message(paste("\nNo CRS detected for in_aoi, setting to EPSG", epsg, "\n"))
      x <- sf::st_set_crs(x, epsg)
      
    } else if(sf::st_crs(x) != sf::st_crs(epsg)) {
      x <- sf::st_transform(x, epsg)
    }
    x <- sf::st_make_valid(x)
  })
  
  # Get largest bbox for downloading layers
  box <- sapply(study_area, st_bbox)
  box <- st_as_sfc(st_bbox(c(
    xmin = min(box["xmin", ]), xmax = max(box["xmax", ]), 
    ymin = min(box["ymin", ]), ymax = max(box["ymax", ])), crs = st_crs(epsg)))
    
  suppressMessages({
    # Download BEC, transform if necessary, and clip to AOI
    cat("\nDownloading BEC layer\n")
    bec_sf <- bcmaps::bec(class = "sf")
    if(sf::st_crs(bec_sf) != sf::st_crs(study_area[[1]])) 
      bec_sf <- sf::st_transform(bec_sf, epsg)
    bec_sf <- lapply(study_area, function(x) {
      sf::st_set_agr(bec_sf, "constant") %>% 
        sf::st_intersection(x) %>%
        dplyr::group_by(MAP_LABEL) %>% 
        dplyr::summarise(.groups = "drop") %>% 
        st_force_poly()})
    
    # Download TEM polygon
    cat("Downloading TEM layer\n")
    tem <- bcdata::bcdc_query_geodata(
      "0a83163b-a62f-4ce6-a9a1-21c228b0c0a3", crs = epsg) %>%
      bcdata::filter(bcdata::INTERSECTS(box)) %>%
      bcdata::collect() %>% 
      sf::st_set_agr("constant") 
    
    # Trim TEM polygon to individual AOI shapes
    tem <- sapply(names(study_area), function(x) {
      if(nrow(tem) > 0) {
        tem <- sf::st_intersection(tem, study_area[[x]]) %>% st_force_poly()
        sf::st_write(tem, file.path(out_path[[x]], "tem.gpkg"),
                     delete_dsn = TRUE, quiet = TRUE)
      } else tem <- tem
      return(tem)}, simplify = FALSE, USE.NAMES = TRUE)
    
    # Adjust BEC subzone lines to match TEM since TEM is higher accuracy
    lapply(names(tem), function(x) {
      
      if(nrow(tem[[x]]) > 0 && 
         all(unique(bec_sf[[x]]$MAP_LABEL) %in% unique(tem[[x]]$BIOGEOCLIMATIC_LBL))) {
        bec_fix <- tem[[x]] %>% dplyr::select(BIOGEOCLIMATIC_LBL) %>% 
          dplyr::group_by(BIOGEOCLIMATIC_LBL) %>% 
          dplyr::summarise(.groups = "drop") %>% st_force_poly()
        if(any(is.na(bec_fix$BIOGEOCLIMATIC_LBL))) {
          bec_sf[[x]] <- sf::st_set_agr(bec_fix, "constant") %>% 
            sf::st_intersection(
              sf::st_set_agr(bec_sf[[x]][, "MAP_LABEL"], "constant")) %>% 
            dplyr::mutate(BIOGEOCLIMATIC_LBL = ifelse(
              is.na(BIOGEOCLIMATIC_LBL), MAP_LABEL, BIOGEOCLIMATIC_LBL)) %>% 
            dplyr::group_by(BIOGEOCLIMATIC_LBL) %>% 
            dplyr::summarise(.groups = "drop") %>% 
            dplyr::rename(MAP_LABEL = BIOGEOCLIMATIC_LBL) %>% st_force_poly()
        } else bec_sf[[x]] <- dplyr::rename(bec_fix, MAP_LABEL = BIOGEOCLIMATIC_LBL)
      }
      sf::st_write(bec_sf[[x]], file.path(out_path[[x]], "bec.gpkg"), 
                   delete_dsn = TRUE, quiet = TRUE)
    })
    
    # Download VRI
    cat("Downloading VRI layer\n")
    vri <- bcdata::bcdc_query_geodata(
      "2ebb35d8-c82f-4a17-9c96-612ac3532d55", crs = epsg) %>% 
      bcdata::filter(bcdata::INTERSECTS(box)) %>%
      bcdata::collect() %>% 
      sf::st_set_agr("constant") 
    
    # Trim VRI polygon to individual AOI polygons
    future::plan(sequential)
    vri <- sapply(names(study_area), function(x) {
      if(nrow(vri) > 0) {
        vri <- sf::st_intersection(vri, study_area[[x]]) %>% st_force_poly()
        sf::st_write(vri, file.path(out_path[[x]], "vri_full.gpkg"), 
                     delete_dsn = TRUE, quiet = TRUE)
        sf::st_write(dplyr::select(vri, "BCLCS_LEVEL_2"), 
                     file.path(out_path[[x]], "vri_trees.gpkg"), # Treed sites
                     delete_dsn = TRUE, quiet = TRUE)
      } else vri <- vri
      return(vri)}, simplify = FALSE, USE.NAMES = TRUE)
    
    # Download recent cutblocks layer
    # Uses date filter which filters cutblock ages less than 20 years, or 7305 days
    cat("Downloading cutblock layer\n")
    cutblocks <- bcdata::bcdc_query_geodata(
      "b1b647a6-f271-42e0-9cd0-89ec24bce9f7", crs = epsg) %>% 
      bcdata::filter(bcdata::INTERSECTS(box)) %>%
      bcdata::collect() %>% 
      sf::st_set_agr("constant") 
    
    # Trim cutblock layer to individual AOI polygons
    cutblocks <- sapply(names(study_area), function(x) {
      if(nrow(cutblocks) > 0) {
        cutblocks <- sf::st_intersection(cutblocks, study_area[[x]]) %>% 
          st_force_poly() %>% 
          mutate(DISTURBANCE_START_DATE = as.Date(DISTURBANCE_START_DATE),
             DISTURBANCE_END_DATE = as.Date(DISTURBANCE_END_DATE)) %>% 
          dplyr::filter(as.numeric(format(Sys.time(), "%Y")) - HARVEST_YEAR <= 20)
        sf::st_write(cutblocks, file.path(out_path[[x]], "young_cutblocks.gpkg"), 
                     delete_dsn = TRUE, quiet = TRUE)
      } else cutblocks <- cutblocks
      return(cutblocks)}, simplify = FALSE, USE.NAMES = TRUE)
    
    # Download water layers, requires merging multiple layers
    cat("Downloading water layers\n")
    
    # Use future package to efficiently download multiple water layers
    water_records <- c(lakes = "cb1e3aba-d3fe-4de1-a2d4-b8b6650fb1f6",
                       rivers = "f7dac054-efbf-402f-ab62-6fc4b32a619e",
                       wetlands = "93b413d8-1840-4770-9629-641d74bd1cc6") 
    
    # Quickly downloads the different layers
    future::plan(multisession)
    waterbodies <- future_lapply(names(water_records), function(x) {
      bcdata::bcdc_query_geodata(water_records[[x]], crs = epsg) %>%
        bcdata::filter(bcdata::INTERSECTS(box)) %>%
        bcdata::collect() 
    })
    future::plan(sequential)
    
    # Removes list entries with 0 rows of data and then merges them into single
    # sf dataframe
    waterbodies <- Filter(function(x) nrow(x) > 0, waterbodies) %>% 
      do.call(rbind, .) %>% 
      sf::st_set_agr("constant")
    
    # With all waterbodies merged, trim those to the individual AOI polygons
    waterbodies <- sapply(names(study_area), function(x) {
      if(nrow(waterbodies) > 0) {
        waterbodies <- sf::st_intersection(waterbodies, study_area[[x]]) %>% 
          st_force_poly()
        sf::st_write(waterbodies, file.path(out_path[[x]], "water.gpkg"), 
             delete_dsn = TRUE, quiet = TRUE)
      } else waterbodies <- waterbodies
      return(waterbodies)}, simplify = FALSE, USE.NAMES = TRUE)
    
    # Download road network
    cat("Downloading Road network\n")
    road_records <- c(roads = "bb060417-b6e6-4548-b837-f9060d94743e",
                      fsr = "9e5bfa62-2339-445e-bf67-81657180c682")
    
    # Quickly downlaod multiple layers
    future::plan(multisession)
    roads <- future_lapply(names(road_records), function(x) {
      bcdata::bcdc_query_geodata(road_records[[x]], crs = epsg) %>% 
        bcdata::filter(bcdata::INTERSECTS(box)) %>% 
        {if(x == "roads") {
          # Digital road atlas has too many roads in it, filter to only include
          # named roads
          bcdata::filter(., ROAD_NAME_ID > 0) %>% 
            bcdata::collect() %>% 
            dplyr::select(id, ROAD_NAME_FULL, FEATURE_LENGTH_M) %>% 
            dplyr::rename(NAME = ROAD_NAME_FULL)
          
        } else {
          # Filter forest service road layer to only include active roads
          bcdata::filter(., LIFE_CYCLE_STATUS_CODE == "ACTIVE") %>% 
            bcdata::collect() %>% 
            dplyr::select(id, MAP_LABEL, FEATURE_LENGTH_M) %>% 
            dplyr::rename(NAME = MAP_LABEL)
        }}
    }) 
    future::plan(sequential)
    
    # Filter any list items with 0 rows and combine to a single sf dataframe
    roads <- Filter(function(x) nrow(x) > 0, roads) %>% 
      do.call(rbind, .) %>% 
      sf::st_set_agr("constant")
    
    # With all roads combined, trim roads to individual AOI polygons
    roads <- sapply(names(study_area), function(x) {
      if(nrow(roads) > 0) {
        roads <- sf::st_intersection(roads, study_area[[x]])  %>% 
          sf::st_cast("MULTILINESTRING")
        sf::st_write(roads, file.path(out_path[[x]], "road_network.gpkg"), 
                     delete_dsn = TRUE, quiet = TRUE)
      } else roads <- roads
      return(roads)}, simplify = FALSE, USE.NAMES = TRUE)
    
    # Download fire polygons
    cat("Downloading Fire areas\n")
    fire_records <- c(current = "cdfc2d7b-c046-4bf0-90ac-4897232619e1", 
                      historical = "22c7cb44-1463-48f7-8e47-88857f207702")
    
    # Quickly download multiple layers
    future::plan(multisession)
    fires <- future_lapply(fire_records, function(x) {
      bcdata::bcdc_query_geodata(x, crs = epsg) %>%
        bcdata::filter(bcdata::INTERSECTS(box)) %>%
        bcdata::collect()
    })
    future::plan(sequential)
    
    # Remove entries with 0 rows of data and combine to single sf dataframe
    fires <- Filter(function(x) nrow(x) > 0, fires) %>% 
      do.call(rbind, .) %>% 
      sf::st_set_agr("constant")
    
    # Trim merged fire area to individual AOI polygons, also filter fires to 
    # only include 20 year old fires or less.
    fires <- sapply(names(study_area), function(x) {
      if(nrow(fires) > 0) {
        fires <- sf::st_intersection(fires, study_area[[x]]) %>% 
          dplyr::select(id, FIRE_NUMBER, VERSION_NUMBER, FIRE_YEAR, 
                        FIRE_SIZE_HECTARES, LOAD_DATE) %>% 
          dplyr::filter(as.numeric(format(Sys.time(), "%Y")) - FIRE_YEAR <= 20) %>% 
          st_force_poly()
        sf::st_write(fires, file.path(out_path[[x]], "fires.gpkg"), 
                     delete_dsn = TRUE, quiet = TRUE)
      } else fires <- fires
      return(fires)}, simplify = FALSE, USE.NAMES = TRUE)
    
    # Now, refactor final results into proper list for output
    pre_out <- list(bec = bec_sf, tem = tem, vri = vri, cutblocks = cutblocks, 
                water = waterbodies, roads = roads, fires = fires)
    out <- sapply(names(study_area), function(x) {
      lapply(pre_out, "[[", x)}, simplify = FALSE, USE.NAMES = TRUE)
    
    if(names(out) == rand_name)
      out <- magrittr::set_names(out, NULL)
    
  })
  return(out)
}

```

We can define input AOI's at each resolution and run the function to save all of the downloaded files. If there are only some subzones of interest, the raster files can be updated to that extent here.

```{r Run Function}

# Define the input AOI files
aoi_shapes <- lapply(
  list.files(shp_dir, pattern = "aoi.gpkg", full.names = TRUE, recursive = TRUE),
  st_read, quiet = TRUE) %>% magrittr::set_names(dir(shp_dir)) %>% 
  lapply(st_geometry)

# Run the function in a loop for multiple input AOI's (function will default
# out_path designation to the folder of in_aoi if in_aoi is a file path)
bc_shapes <- get_bc_shapes(aoi_shapes, out_path = shp_dir)

```
